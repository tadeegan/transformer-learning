ViT(
  (positional_embedding): PositionalEmbedding2d()
  (encoder_blocks): Sequential(
    (0): TransformerEncoderBlock(
      (norm1): LayerNorm((28,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((28,), eps=1e-05, elementwise_affine=True)
      (msa): MultiHeadSelfAttention(
        (lin_k): Linear(in_features=28, out_features=28, bias=True)
        (lin_q): Linear(in_features=28, out_features=28, bias=True)
        (lin_v): Linear(in_features=28, out_features=28, bias=True)
      )
      (MLP): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=28, out_features=28, bias=True)
          (1): Linear(in_features=28, out_features=28, bias=True)
        )
      )
    )
    (1): TransformerEncoderBlock(
      (norm1): LayerNorm((28,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((28,), eps=1e-05, elementwise_affine=True)
      (msa): MultiHeadSelfAttention(
        (lin_k): Linear(in_features=28, out_features=28, bias=True)
        (lin_q): Linear(in_features=28, out_features=28, bias=True)
        (lin_v): Linear(in_features=28, out_features=28, bias=True)
      )
      (MLP): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=28, out_features=28, bias=True)
          (1): Linear(in_features=28, out_features=28, bias=True)
        )
      )
    )
    (2): TransformerEncoderBlock(
      (norm1): LayerNorm((28,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((28,), eps=1e-05, elementwise_affine=True)
      (msa): MultiHeadSelfAttention(
        (lin_k): Linear(in_features=28, out_features=28, bias=True)
        (lin_q): Linear(in_features=28, out_features=28, bias=True)
        (lin_v): Linear(in_features=28, out_features=28, bias=True)
      )
      (MLP): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=28, out_features=28, bias=True)
          (1): Linear(in_features=28, out_features=28, bias=True)
        )
      )
    )
    (3): TransformerEncoderBlock(
      (norm1): LayerNorm((28,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((28,), eps=1e-05, elementwise_affine=True)
      (msa): MultiHeadSelfAttention(
        (lin_k): Linear(in_features=28, out_features=28, bias=True)
        (lin_q): Linear(in_features=28, out_features=28, bias=True)
        (lin_v): Linear(in_features=28, out_features=28, bias=True)
      )
      (MLP): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=28, out_features=28, bias=True)
          (1): Linear(in_features=28, out_features=28, bias=True)
        )
      )
    )
  )
  (final_mlp): MLP(
    (layers): ModuleList(
      (0): Linear(in_features=28, out_features=10, bias=True)
    )
  )
)
patches_train.shape: (60000, 49, 16)
 36%|███████████████████████████████████████████████████████████████▎                                                                                                                | 36/100 [00:01<00:02, 26.53it/s]
loss: [100]: 229.77926635742188
Valition (on train):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 31.75it/s]
  4%|███████                                                                                                                                                                          | 4/100 [00:00<00:02, 38.40it/s]

 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                          | 76/100 [00:02<00:00, 37.62it/s]
loss: [200]: 229.37954711914062
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 36.27it/s]
 44%|█████████████████████████████████████████████████████████████████████████████▍                                                                                                  | 44/100 [00:01<00:01, 37.77it/s]
loss: [300]: 223.83615112304688
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 37.31it/s]

 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 84/100 [00:02<00:00, 35.69it/s]
loss: [400]: 220.9356689453125
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 35.72it/s]
 39%|████████████████████████████████████████████████████████████████████▋                                                                                                           | 39/100 [00:01<00:02, 27.84it/s]
loss: [500]: 219.6830596923828
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 31.65it/s]
  0%|                                                                                                                                                                                         | 0/100 [00:00<?, ?it/s]
Valition (on test):

 56%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                             | 56/100 [00:02<00:01, 28.73it/s]
loss: [600]: 217.83241271972656
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 30.64it/s]

 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉              | 92/100 [00:02<00:00, 36.40it/s]
loss: [700]: 215.62330627441406
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 35.15it/s]
 51%|█████████████████████████████████████████████████████████████████████████████████████████▊                                                                                      | 51/100 [00:01<00:01, 34.17it/s]
loss: [800]: 211.79637145996094
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 33.76it/s]

 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 84/100 [00:02<00:00, 37.28it/s]
loss: [900]: 206.830322265625
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 35.43it/s]
 52%|███████████████████████████████████████████████████████████████████████████████████████████▌                                                                                    | 52/100 [00:01<00:01, 37.51it/s]
loss: [1000]: 201.41159057617188
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 36.64it/s]

 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉              | 92/100 [00:02<00:00, 36.47it/s]
loss: [1100]: 197.2039337158203
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 36.54it/s]
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                             | 56/100 [00:01<00:01, 36.83it/s]
loss: [1200]: 196.0028839111328
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 36.72it/s]

 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉       | 96/100 [00:02<00:00, 36.13it/s]
loss: [1300]: 199.66656494140625
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 36.64it/s]
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                               | 64/100 [00:01<00:00, 36.96it/s]
loss: [1400]: 194.86553955078125
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 36.45it/s]

100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 36.67it/s]
loss: [1500]: 196.40501403808594
Valition (on train):
Valition (on test):
Accuracy (on test): 0.54
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                        | 68/100 [00:01<00:00, 36.74it/s]
loss: [1600]: 194.0476837158203
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 36.72it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 36.73it/s]
  0%|                                                                                                                                                                                         | 0/100 [00:00<?, ?it/s]
loss: [1700]: 192.31150817871094
Valition (on train):
Valition (on test):

 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                 | 72/100 [00:01<00:00, 35.45it/s]
loss: [1800]: 188.67774963378906
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 35.47it/s]

 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                 | 72/100 [00:02<00:01, 27.12it/s]
loss: [1900]: 187.36129760742188
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 29.71it/s]
 39%|████████████████████████████████████████████████████████████████████▋                                                                                                           | 39/100 [00:01<00:01, 35.63it/s]
Traceback (most recent call last):
  File "/Users/tdeegan/dev/transformers/main.py", line 130, in <module>
    y_pred = model(x)
  File "/Users/tdeegan/dev/transformers/vit.py", line 119, in __call__
    x = self.encoder_blocks(x)
  File "/Users/tdeegan/Library/Python/3.10/lib/python/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/Users/tdeegan/Library/Python/3.10/lib/python/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/Users/tdeegan/dev/transformers/vit.py", line 45, in __call__
    x = self.msa(self.norm1(inputs)) + inputs
  File "/Users/tdeegan/dev/transformers/vit.py", line 67, in __call__
    x = torch.matmul(x, v)
KeyboardInterrupt