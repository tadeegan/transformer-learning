ViT(
  (positional_embedding): PositionalEmbedding2d()
  (encoder_blocks): Sequential(
    (0): TransformerEncoderBlock(
      (norm1): LayerNorm((28,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((28,), eps=1e-05, elementwise_affine=True)
      (msa): MultiHeadSelfAttention(
        (lin_k): Linear(in_features=28, out_features=28, bias=True)
        (lin_q): Linear(in_features=28, out_features=28, bias=True)
        (lin_v): Linear(in_features=28, out_features=28, bias=True)
      )
      (MLP): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=28, out_features=28, bias=True)
          (1): Linear(in_features=28, out_features=28, bias=True)
        )
      )
    )
    (1): TransformerEncoderBlock(
      (norm1): LayerNorm((28,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((28,), eps=1e-05, elementwise_affine=True)
      (msa): MultiHeadSelfAttention(
        (lin_k): Linear(in_features=28, out_features=28, bias=True)
        (lin_q): Linear(in_features=28, out_features=28, bias=True)
        (lin_v): Linear(in_features=28, out_features=28, bias=True)
      )
      (MLP): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=28, out_features=28, bias=True)
          (1): Linear(in_features=28, out_features=28, bias=True)
        )
      )
    )
    (2): TransformerEncoderBlock(
      (norm1): LayerNorm((28,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((28,), eps=1e-05, elementwise_affine=True)
      (msa): MultiHeadSelfAttention(
        (lin_k): Linear(in_features=28, out_features=28, bias=True)
        (lin_q): Linear(in_features=28, out_features=28, bias=True)
        (lin_v): Linear(in_features=28, out_features=28, bias=True)
      )
      (MLP): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=28, out_features=28, bias=True)
          (1): Linear(in_features=28, out_features=28, bias=True)
        )
      )
    )
    (3): TransformerEncoderBlock(
      (norm1): LayerNorm((28,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((28,), eps=1e-05, elementwise_affine=True)
      (msa): MultiHeadSelfAttention(
        (lin_k): Linear(in_features=28, out_features=28, bias=True)
        (lin_q): Linear(in_features=28, out_features=28, bias=True)
        (lin_v): Linear(in_features=28, out_features=28, bias=True)
      )
      (MLP): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=28, out_features=28, bias=True)
          (1): Linear(in_features=28, out_features=28, bias=True)
        )
      )
    )
  )
  (final_mlp): MLP(
    (layers): ModuleList(
      (0): Linear(in_features=28, out_features=10, bias=True)
    )
  )
)
patches_train.shape: (60000, 49, 16)







 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊            | 558/600 [00:15<00:01, 37.82it/s]
loss: [600]: 196.65768432617188
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:16<00:00, 35.80it/s]








 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊ | 596/600 [00:16<00:00, 35.79it/s]
loss: [1200]: 183.9198760986328
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:16<00:00, 35.42it/s]







 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊        | 572/600 [00:15<00:00, 35.59it/s]
loss: [1800]: 180.4443817138672
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:16<00:00, 36.00it/s]








 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏   | 587/600 [00:16<00:00, 35.25it/s]
loss: [2400]: 196.89364624023438
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:17<00:00, 35.12it/s]







 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████              | 552/600 [00:15<00:01, 36.73it/s]
loss: [3000]: 234.11839294433594
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:16<00:00, 35.48it/s]








100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:16<00:00, 36.20it/s]
loss: [3600]: 236.11500549316406
Valition (on train):
Valition (on test):
Accuracy (on test): 0.14
Epoch 00006: reducing learning rate of group 0 to 5.0000e-03.







 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊        | 572/600 [00:15<00:00, 36.96it/s]
loss: [4200]: 236.11500549316406
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:16<00:00, 36.74it/s]








 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊        | 572/600 [00:17<00:00, 32.55it/s]
loss: [4800]: 236.11500549316406
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:17<00:00, 33.39it/s]







 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌               | 547/600 [00:15<00:01, 35.25it/s]
loss: [5400]: 236.11500549316406
Valition (on train):
Valition (on test):
Accuracy (on test): 0.14
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:16<00:00, 35.98it/s]








 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏     | 580/600 [00:15<00:00, 37.52it/s]
loss: [6000]: 236.11500549316406
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:16<00:00, 36.36it/s]







 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████              | 552/600 [00:15<00:01, 37.04it/s]
loss: [6600]: 236.11500549316406
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:16<00:00, 35.88it/s]







 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████              | 552/600 [00:14<00:01, 38.99it/s]
loss: [7200]: 236.11500549316406
Valition (on train):
Valition (on test):
Accuracy (on test): 0.14
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:15<00:00, 37.50it/s]








 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 588/600 [00:16<00:00, 36.73it/s]
loss: [7800]: 236.11500549316406
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:17<00:00, 35.26it/s]







 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏            | 556/600 [00:15<00:01, 37.75it/s]
loss: [8400]: 236.11500549316406
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:16<00:00, 36.59it/s]







100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:16<00:00, 36.34it/s]
  0%|                                                                                                                                                                                         | 0/600 [00:00<?, ?it/s]
loss: [9000]: 236.11500549316406
Valition (on train):
Valition (on test):
Accuracy (on test): 0.14







100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:15<00:00, 37.88it/s]
  1%|██▎                                                                                                                                                                              | 8/600 [00:00<00:16, 36.69it/s]
loss: [9600]: 236.11500549316406
Valition (on train):
Valition (on test):








 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎    | 584/600 [00:15<00:00, 38.33it/s]
loss: [10200]: 236.11500549316406
Valition (on train):
Valition (on test):
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:16<00:00, 36.79it/s]

 34%|███████████████████████████████████████████████████████████▏                                                                                                                   | 203/600 [00:05<00:10, 37.39it/s]
Traceback (most recent call last):
  File "/Users/tdeegan/dev/transformers/main.py", line 138, in <module>
    loss.backward()
  File "/Users/tdeegan/Library/Python/3.10/lib/python/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/Users/tdeegan/Library/Python/3.10/lib/python/site-packages/torch/autograd/__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt