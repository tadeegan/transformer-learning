ViT(
  (positional_embedding): PositionalEmbedding2d()
  (encoder_blocks): Sequential(
    (0): TransformerEncoderBlock(
      (norm1): LayerNorm((28,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((28,), eps=1e-05, elementwise_affine=True)
      (msa): MultiHeadSelfAttention(
        (lin_k): Linear(in_features=28, out_features=28, bias=True)
        (lin_q): Linear(in_features=28, out_features=28, bias=True)
        (lin_v): Linear(in_features=28, out_features=28, bias=True)
      )
      (MLP): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=28, out_features=28, bias=True)
          (1): Linear(in_features=28, out_features=28, bias=True)
        )
      )
    )
    (1): TransformerEncoderBlock(
      (norm1): LayerNorm((28,), eps=1e-05, elementwise_affine=True)
      (norm2): LayerNorm((28,), eps=1e-05, elementwise_affine=True)
      (msa): MultiHeadSelfAttention(
        (lin_k): Linear(in_features=28, out_features=28, bias=True)
        (lin_q): Linear(in_features=28, out_features=28, bias=True)
        (lin_v): Linear(in_features=28, out_features=28, bias=True)
      )
      (MLP): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=28, out_features=28, bias=True)
          (1): Linear(in_features=28, out_features=28, bias=True)
        )
      )
    )
  )
  (final_mlp): MLP(
    (layers): ModuleList(
      (0): Linear(in_features=28, out_features=10, bias=True)
    )
  )
)
patches_train.shape: (60000, 49, 16)
learning rate: 0.019047619047619046
final_mlp.layers.0.weight
tensor([[-0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,
          0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,
          0.0000e+00,  0.0000e+00, -0.0000e+00],
        [-0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,
          0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,
          0.0000e+00,  0.0000e+00, -0.0000e+00],
        [-0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,
          0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,
          0.0000e+00,  0.0000e+00, -0.0000e+00],
        [-4.7889e-05,  1.2789e-04, -6.8354e-04,  1.0719e-03, -1.4497e-03,
         -8.7355e-04, -4.9418e-05, -3.0342e-04, -3.6201e-05, -3.8483e-04,
          2.4487e-03, -3.2477e-04, -7.4564e-04,  7.5587e-04, -3.4515e-03,
          2.0046e-03,  2.1470e-03,  1.3645e-03,  2.3766e-03,  1.6975e-03,
          3.6403e-04,  3.4103e-04, -1.2335e-03,  9.5876e-05,  1.0383e-03,
         -3.8675e-04,  2.1733e-03,  1.1379e-03],
        [-0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,
          0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,
          0.0000e+00,  0.0000e+00, -0.0000e+00],
        [ 2.2505e-03, -1.6292e-04, -6.7242e-04, -1.4236e-03,  1.0594e-03,
          4.7922e-05,  1.8837e-03,  6.8583e-04,  3.0231e-04,  4.1371e-04,
         -4.9323e-03,  6.1642e-04,  1.3514e-03, -1.5445e-03,  2.3792e-03,
         -1.7369e-03, -1.5320e-03, -2.5182e-03, -6.5607e-04,  6.1748e-04,
         -1.2831e-03, -1.0836e-03,  5.1980e-04,  4.2921e-04, -3.0089e-03,
          7.2274e-04, -3.2957e-03, -4.0032e-04],
        [-1.2509e-03,  1.4306e-03,  1.1188e-03,  1.3900e-03, -1.4732e-03,
         -3.1975e-06, -1.0786e-03, -1.8990e-03, -9.6604e-04,  1.3574e-03,
          2.4724e-03,  1.2489e-03,  5.0147e-04,  1.0314e-03,  1.5578e-05,
         -1.6950e-04,  4.5166e-04,  3.4547e-03,  3.3969e-04, -8.6473e-04,
          7.9434e-04,  1.1771e-03,  4.7597e-04, -2.1699e-03, -2.3480e-04,
          9.5647e-05, -5.8882e-04, -8.1685e-05],
        [-0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,
          0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,
          0.0000e+00,  0.0000e+00, -0.0000e+00],
        [-7.9570e-04,  3.9284e-04, -7.3208e-04,  8.7635e-04, -1.7496e-03,
         -7.4772e-04,  1.4534e-03, -6.9125e-04, -9.4200e-04, -8.2978e-04,
          2.7837e-03, -3.9392e-04, -8.7235e-04, -5.7130e-05, -1.2418e-03,
          1.6265e-03,  1.7947e-03,  3.4710e-04,  5.4851e-04,  1.6178e-03,
          1.4098e-04,  5.5824e-04, -7.3964e-04,  6.7326e-04, -2.2617e-04,
          5.4139e-04,  1.4742e-03,  1.5117e-03],
        [-0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,
          0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,
          0.0000e+00,  0.0000e+00, -0.0000e+00]])
final_mlp.layers.0.bias
tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.8626e-09,  0.0000e+00,
        -1.8626e-09,  4.6566e-09,  0.0000e+00,  4.1910e-09,  0.0000e+00])
loss: [1]: 230.26168823242188
Valition (on train):
5 -> [0]
0 -> [0]
4 -> [0]
1 -> [0]
9 -> [0]
2 -> [0]
1 -> [0]
3 -> [0]
1 -> [0]
4 -> [0]
Accuracy (on train): 0.13
learning rate: 0.018140589569160995
final_mlp.layers.0.weight
tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-4.8959e-05,  1.2680e-04, -6.8387e-04,  1.0715e-03, -1.4504e-03,
         -8.7085e-04, -4.7624e-05, -3.0493e-04, -3.8450e-05, -3.8536e-04,
          2.4480e-03, -3.2457e-04, -7.4432e-04,  7.5543e-04, -3.4503e-03,
          2.0044e-03,  2.1474e-03,  1.3642e-03,  2.3751e-03,  1.6970e-03,
          3.6573e-04,  3.4101e-04, -1.2338e-03,  9.5437e-05,  1.0357e-03,
         -3.8822e-04,  2.1713e-03,  1.1375e-03],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 2.2505e-03, -1.6192e-04, -6.7250e-04, -1.4233e-03,  1.0598e-03,
          4.6394e-05,  1.8818e-03,  6.8519e-04,  3.0306e-04,  4.1364e-04,
         -4.9308e-03,  6.1700e-04,  1.3501e-03, -1.5437e-03,  2.3790e-03,
         -1.7362e-03, -1.5329e-03, -2.5172e-03, -6.5474e-04,  6.1656e-04,
         -1.2830e-03, -1.0837e-03,  5.1955e-04,  4.2854e-04, -3.0067e-03,
          7.2400e-04, -3.2932e-03, -4.0101e-04],
        [-1.2505e-03,  1.4307e-03,  1.1187e-03,  1.3890e-03, -1.4734e-03,
         -3.5456e-06, -1.0780e-03, -1.8974e-03, -9.6557e-04,  1.3576e-03,
          2.4713e-03,  1.2481e-03,  5.0150e-04,  1.0307e-03,  1.5297e-05,
         -1.6893e-04,  4.5171e-04,  3.4544e-03,  3.3927e-04, -8.6444e-04,
          7.9364e-04,  1.1776e-03,  4.7654e-04, -2.1685e-03, -2.3513e-04,
          9.4892e-05, -5.8976e-04, -8.1706e-05],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-7.9608e-04,  3.9184e-04, -7.3227e-04,  8.7561e-04, -1.7493e-03,
         -7.4609e-04,  1.4547e-03, -6.9115e-04, -9.4346e-04, -8.3035e-04,
          2.7825e-03, -3.9341e-04, -8.7111e-04, -5.8258e-05, -1.2411e-03,
          1.6262e-03,  1.7951e-03,  3.4633e-04,  5.4785e-04,  1.6182e-03,
          1.4173e-04,  5.5812e-04, -7.3976e-04,  6.7326e-04, -2.2742e-04,
          5.3969e-04,  1.4720e-03,  1.5119e-03],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00]])
final_mlp.layers.0.bias
tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00, -4.6566e-09,  0.0000e+00,
         0.0000e+00, -6.0536e-09,  0.0000e+00, -1.3737e-08,  0.0000e+00])
loss: [2]: 230.26168823242188
Valition (on train):
5 -> [0]
0 -> [0]
4 -> [0]
1 -> [0]
9 -> [0]
2 -> [0]
1 -> [0]
3 -> [0]
1 -> [0]
4 -> [0]
Accuracy (on train): 0.13
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 15.49it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 42.20it/s]